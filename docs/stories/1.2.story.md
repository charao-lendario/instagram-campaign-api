# Story 1.2: Endpoint de Scraping -- Buscar Últimos 10 Posts via Apify

## Status: InProgress
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 5

---

## Description

Como analista de campanha, quero que o sistema colete automaticamente os últimos 10 posts de cada perfil monitorado (@charlles.evangelista e @delegadasheila) usando o ator `apify/instagram-post-scraper`, para que eu tenha dados frescos de posts disponíveis para análise de engajamento.

Esta story implementa o serviço de scraping de posts, incluindo mapeamento dos campos retornados pelo Apify para o modelo `Post`, upsert idempotente no Supabase (deduplicação por `instagram_id`), registro de `scraping_runs`, tratamento de erros resiliente, e o endpoint de trigger.

---

## Acceptance Criteria

- [x] **AC1**: Given que `APIFY_TOKEN` está configurado, when `scrape_posts(candidate_username: str) -> list[Post]` é chamado com `"charlles.evangelista"`, then o ator `apify/instagram-post-scraper` é invocado via `apify-client` com input `{"usernames": [candidate_username], "resultsLimit": 10}`, e o resultado é uma lista de no máximo 10 posts mapeados para o modelo `Post`.

- [x] **AC2**: Given que o Apify retorna dados de um post, when o mapeamento é executado, then os seguintes campos são corretamente mapeados para `PostUpsert`:
  - `id` (Apify) → `instagram_id`
  - `url` ou `postUrl` → `url`
  - `shortCode` → `shortcode`
  - `caption` → `caption`
  - `likesCount` → `like_count`
  - `commentsCount` → `comment_count`
  - `type` → `media_type` (mapeado para enum: image/video/carousel/unknown)
  - `isSponsored` → `is_sponsored`
  - `videoViewCount` → `video_view_count`
  - `timestamp` → `posted_at`
  - Objeto completo Apify → `raw_data` (JSONB)
  - `candidate_id` resolvido a partir do `username` via query em `candidates`
  - `scraping_run_id` associado ao `ScrapingRun` corrente

- [x] **AC3**: Given que um post já existe no banco (mesmo `instagram_id`), when `scrape_posts()` é chamado novamente, then o post é atualizado (upsert) com os novos valores de `like_count`, `comment_count`, `scraped_at`, e `updated_at`. Nenhum registro duplicado é criado.

- [x] **AC4**: Given que um `ScrapingRun` com status `running` é criado antes do scraping iniciar, when `scrape_posts()` completa com sucesso, then `scraping_runs.posts_scraped` é incrementado com o número de posts retornados e o status permanece `running` (será fechado pelo pipeline completo na Story 1.7).

- [x] **AC5**: Given que o ator Apify falha (timeout, rate limit, actor error), when `scrape_posts()` captura a exceção, then: (a) a exceção é logada com structured logging contendo `candidate_username`, `actor_id`, e `error_message`; (b) o erro é adicionado ao `scraping_runs.errors` JSONB com campos `candidate`, `phase: "post_scraping"`, `message`, e `timestamp`; (c) uma exceção descritiva é propagada para o chamador; (d) a aplicação NÃO crasha.

- [x] **AC6**: Given que `POST /api/v1/scraping/posts` é chamado sem body, when processado, then: (a) um novo `ScrapingRun` é criado com `status: "running"`; (b) `scrape_posts()` é invocado para cada candidato ativo (`is_active = True`) em `candidates`; (c) a resposta `202 Accepted` é retornada com `{"run_id": "<uuid>", "status": "started", "candidates": ["charlles.evangelista", "delegadasheila"]}`; (d) o scraping pode continuar em background (mas para MVP pode ser síncrono dado que Railway não tem limite de request timeout restritivo).

- [x] **AC7**: Given que os unit tests existem em `tests/test_scraping.py`, when `pytest tests/test_scraping.py -k "post"` é executado, then todos passam. Os testes cobrem:
  - Scraping bem-sucedido com mock do `apify-client` retornando 10 posts
  - Deduplicação: segundo scraping do mesmo post atualiza ao invés de duplicar
  - Falha do ator Apify: exceção é propagada corretamente e erros logados
  - Mapeamento correto de campos (especialmente `media_type` e campos opcionais)

---

## Scope

### IN
- `app/services/scraping.py` -- função `scrape_posts(candidate_username: str, run_id: UUID) -> list[Post]`
- Helper interno para resolver `candidate_id` a partir de `username`
- Helper interno para mapear resposta Apify para `PostUpsert`
- Upsert de posts via `supabase.table("posts").upsert(..., on_conflict="instagram_id")`
- Criação e atualização de `ScrapingRun`
- `app/routers/scraping.py` -- endpoint `POST /api/v1/scraping/posts`
- `tests/test_scraping.py` -- seção de testes de post scraping

### OUT
- Scraping de comentários (Story 1.3)
- Pipeline completo (Story 1.7)
- Análise de sentimento (Stories 1.4, 1.5)
- Scraping paralelo/assíncrono avançado (MVP é síncrono sequencial)

---

## Dependencies

- Story 1.1 concluída (configuração, modelos, cliente Supabase)
- Supabase com seed data dos candidatos (`charlles.evangelista`, `delegadasheila`)
- Conta Apify com token válido e acesso ao ator `apify/instagram-post-scraper`

---

## Technical Notes

### Apify Client Pattern (architecture.md Seção 6.1)

```python
from apify_client import ApifyClient
from app.core.config import settings

def _get_apify_client() -> ApifyClient:
    return ApifyClient(settings.APIFY_TOKEN)

# Actor invocation (synchronous -- waits for completion)
client = _get_apify_client()
run = client.actor("apify/instagram-post-scraper").call(
    run_input={
        "usernames": [candidate_username],
        "resultsLimit": 10
    }
)
items = list(client.dataset(run["defaultDatasetId"]).iterate_items())
```

### Upsert Pattern (SCHEMA.md Seção 9)

```python
supabase.table("posts").upsert(
    post_data_dict,
    on_conflict="instagram_id"
).execute()
```

O upsert atualiza: `like_count`, `comment_count`, `scraped_at`, `updated_at`.

### Estrutura do ScrapingRun (SCHEMA.md Seção 3.2)

Campos do `errors` JSONB:
```json
[
  {
    "candidate": "charlles.evangelista",
    "phase": "post_scraping",
    "message": "Apify actor timeout after 60s",
    "timestamp": "2026-02-21T10:00:00Z"
  }
]
```

### Endpoints Envolvidos (architecture.md Seção 3.2.2)

- `POST /api/v1/scraping/posts` -- 202 Accepted
  - Response: `{"run_id": "uuid", "status": "started", "candidates": [...]}`

### Tabelas Envolvidas
- `candidates` (SELECT WHERE is_active = TRUE)
- `posts` (UPSERT ON CONFLICT instagram_id)
- `scraping_runs` (INSERT + UPDATE posts_scraped + UPDATE errors)

### PRD References
- FR-001: Instagram Post Scraping -- 10 posts por candidato via instagram-post-scraper
- CON-001: Scraping exclusivamente via Apify
- CON-002: Exatamente 2 perfis monitorados (MVP)
- NFR-005: Error Resilience -- falha não crasha, erros logados
- NFR-009: Cost Efficiency -- máximo 2 actor runs para posts (1 por candidato)

### Considerações de Custo (NFR-009)
- 1 actor run por candidato = 2 runs por ciclo de scraping de posts
- `resultsLimit: 10` garante que não ultrapassa o necessário
- ID do ator deve ser configurável via settings (`APIFY_POST_ACTOR_ID`, default: `"apify/instagram-post-scraper"`)

---

## Risks

| Risco | Probabilidade | Impacto | Mitigacao |
|-------|---------------|---------|-----------|
| Apify rate limit ou bloqueio do ator instagram-post-scraper | Media | Alto | Retry no proximo ciclo (NFR-005); error logging em scraping_runs.errors; actor ID configuravel para troca rapida |
| Mudanca na estrutura de dados retornada pelo Apify | Baixa | Alto | raw_data preserva resposta original para debug; mapeamento isolado em helper dedicado facilita ajuste |
| Custo de actor runs acima do esperado | Baixa | Medio | resultsLimit: 10 controla volume; 2 runs por ciclo (1 por candidato); monitorar via scraping_runs |
| Timeout do actor.call() bloqueante | Media | Medio | Para MVP e aceitavel; documentar necessidade de timeout configuravel para producao |

---

## File List

| Arquivo | Acao | Status |
|---------|------|--------|
| `app/services/scraping.py` | Criar -- `scrape_posts()` e helpers | Criado |
| `app/routers/scraping.py` | Criar -- `POST /api/v1/scraping/posts` | Criado |
| `app/main.py` | Modificar -- registrar `scraping.router` | Modificado |
| `app/core/config.py` | Modificar -- adicionar `APIFY_POST_ACTOR_ID` e `APIFY_COMMENT_ACTOR_ID` | Modificado |
| `tests/test_scraping.py` | Criar -- testes de post scraping | Criado |

---

## Dev Notes

- `APIFY_POST_ACTOR_ID` adicionado ao `config.py` com default `"apify/instagram-post-scraper"` (NFR-009)
- `APIFY_COMMENT_ACTOR_ID` adicionado ao `config.py` com default `"apify/instagram-comment-scraper"` (antecipando Story 1.3)
- Usa `ApifyClient` (sync) conforme architecture.md -- `actor.call()` e bloqueante, aceitavel para MVP
- `_map_apify_post()` trata tanto ISO timestamps quanto unix timestamps no campo `timestamp`
- `_MEDIA_TYPE_MAP` mapeia tanto PascalCase ("Image") quanto lowercase ("image") e "Sidecar" -> carousel
- `_update_run_posts_scraped` faz fetch-then-update pois Supabase nao suporta increment nativo via SDK
- `_append_run_error` faz fetch-then-append no JSONB errors array pelo mesmo motivo
- Router `trigger_post_scraping` continua para o proximo candidato se um falhar (resiliencia parcial)
- 23 testes criados: 12 para Story 1.2 (posts) + 11 para Story 1.3 (comments) -- todos passam

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
| 2026-02-21 | Pax (PO) | Validacao: GO 9/10. Adicionada secao Risks. Status Draft -> Ready |
| 2026-02-21 | Dex (Dev) | Implementacao completa: servico, router, testes. Status Ready -> InProgress. Todos ACs atendidos. |

---

## Validation

| # | Criterio | Resultado |
|---|----------|-----------|
| 1 | Titulo claro e objetivo | PASS |
| 2 | Descricao completa | PASS |
| 3 | ACs testaveis (Given/When/Then) | PASS |
| 4 | Escopo bem definido (IN/OUT) | PASS |
| 5 | Dependencias mapeadas | PASS |
| 6 | Estimativa de complexidade | PASS |
| 7 | Valor de negocio | PASS |
| 8 | Riscos documentados | PASS (adicionados durante validacao) |
| 9 | Criterios de Done | PASS |
| 10 | Alinhamento com PRD/Epic | PASS |

**Score: 9/10 -> GO**
**Validador:** Pax (PO)
**Data:** 2026-02-21
**Observacoes:** Secao Risks estava ausente e foi adicionada durante validacao. Campos do AC2 estao alinhados com SCHEMA.md (shortcode, is_sponsored, video_view_count, raw_data). PRD References verificados: FR-001, CON-001, CON-002, NFR-005, NFR-009.
