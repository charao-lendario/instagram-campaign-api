# Story 1.3: Endpoint de Scraping -- Buscar Comentários de Cada Post via Apify

## Status: Draft
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 5

---

## Description

Como analista de campanha, quero que todos os comentários de cada post coletado sejam buscados automaticamente via Apify `instagram-comment-scraper`, para que análise de sentimento e extração de temas tenham dados completos para processar.

Esta story estende o serviço de scraping com a função de coleta de comentários, incluindo mapeamento dos campos do Apify para o modelo `Comment`, upsert idempotente (deduplicação por `instagram_id`), tratamento de falhas parciais (falha em um post não para o processo), atualização do `ScrapingRun`, e o endpoint de trigger.

---

## Acceptance Criteria

- [ ] **AC1**: Given que posts existem no banco, when `scrape_comments(post_url: str, post_id: UUID, run_id: UUID) -> list[Comment]` é chamado, then o ator `apify/instagram-comment-scraper` é invocado com input `{"directUrls": [post_url], "resultsLimit": 500}`, e o resultado é uma lista de comentários mapeados para o modelo `Comment`.

- [ ] **AC2**: Given que o Apify retorna dados de um comentário, when o mapeamento é executado, then os seguintes campos são corretamente mapeados para `CommentUpsert`:
  - `id` (Apify) → `instagram_id`
  - `text` → `text`
  - `ownerUsername` → `author_username`
  - `timestamp` → `commented_at`
  - `likesCount` → `like_count`
  - `replies` (count ou lista) → `reply_count`
  - Objeto completo Apify → `raw_data` (JSONB)
  - `post_id` passado como parâmetro
  - `scraping_run_id` do run corrente

- [ ] **AC3**: Given que um comentário já existe no banco (mesmo `instagram_id`), when `scrape_comments()` é chamado novamente, then o comentário é atualizado (upsert) com o novo valor de `like_count` e `scraped_at`. Nenhum registro duplicado é criado.

- [ ] **AC4**: Given uma lista de posts, when `scrape_all_comments(posts: list[Post], run_id: UUID) -> int` é chamado, then: (a) `scrape_comments()` é invocado sequencialmente para cada post; (b) se um post falha, o erro é logado e adicionado ao `scraping_runs.errors`, mas o processo continua para os posts restantes; (c) o total de comentários coletados com sucesso é retornado; (d) `scraping_runs.comments_scraped` é atualizado com o total.

- [ ] **AC5**: Given que o ator Apify falha para um post específico (timeout, rate limit), when a exceção é capturada em `scrape_comments()`, then: (a) o erro é logado com `post_url`, `post_id`, `actor_id`, e `error_message` em structured logging; (b) o erro é adicionado ao `scraping_runs.errors` JSONB com `phase: "comment_scraping"`; (c) a função retorna lista vazia `[]` para esse post; (d) `scrape_all_comments()` continua para os próximos posts.

- [ ] **AC6**: Given que `POST /api/v1/scraping/comments` é chamado sem body, when processado, then: (a) os posts elegíveis são identificados (todos os posts existentes no banco ou posts com `scraped_at` mais antigo que o threshold de staleness configurado -- default: todos os posts do run mais recente); (b) `scrape_all_comments()` é invocado; (c) a resposta `202 Accepted` é retornada com `{"run_id": "<uuid>", "status": "started", "posts_queued": <N>}`.

- [ ] **AC7**: Given que os unit tests existem em `tests/test_scraping.py`, when `pytest tests/test_scraping.py -k "comment"` é executado, then todos passam. Os testes cobrem:
  - Scraping bem-sucedido de comentários com mock do `apify-client` retornando 50 comentários
  - Deduplicação: segundo scraping do mesmo comentário atualiza ao invés de duplicar
  - Falha parcial: falha em 1 de 3 posts -- os outros 2 são processados, erro logado
  - `scrape_all_comments()`: retorna total correto de comentários coletados

---

## Scope

### IN
- `app/services/scraping.py` -- adicionar `scrape_comments()` e `scrape_all_comments()`
- Helper interno para mapear resposta Apify de comentário para `CommentUpsert`
- Upsert de comentários via `supabase.table("comments").upsert(..., on_conflict="instagram_id")`
- Atualização de `ScrapingRun.comments_scraped` e `errors`
- `app/routers/scraping.py` -- adicionar `POST /api/v1/scraping/comments`
- `tests/test_scraping.py` -- seção de testes de comment scraping

### OUT
- Análise de sentimento dos comentários (Stories 1.4, 1.5)
- Extração de temas (Story 1.6)
- Scraping em paralelo (MVP é sequencial por post)
- Paginação de comentários além de `resultsLimit: 500`

---

## Dependencies

- Story 1.1 concluída (configuração, modelos, cliente Supabase)
- Story 1.2 concluída (posts devem existir no banco para buscar comentários)
- Conta Apify com acesso ao ator `apify/instagram-comment-scraper`

---

## Technical Notes

### Apify Comment Scraper Input (architecture.md Seção 6.1)

```python
run = client.actor("apify/instagram-comment-scraper").call(
    run_input={
        "directUrls": [post_url],
        "resultsLimit": 500
    }
)
items = list(client.dataset(run["defaultDatasetId"]).iterate_items())
```

### Lógica de Falha Parcial (NFR-005)

O loop em `scrape_all_comments()` usa try/except individual por post:
```python
for post in posts:
    try:
        comments = scrape_comments(post.url, post.id, run_id)
        total_scraped += len(comments)
    except Exception as e:
        logger.error("comment_scraping_failed", post_id=str(post.id), error=str(e))
        # append to errors JSONB, continue loop
```

### Upsert de Comentários (SCHEMA.md Seção 9)

```python
supabase.table("comments").upsert(
    comment_data_dict,
    on_conflict="instagram_id"
).execute()
```

O upsert atualiza: `like_count`, `scraped_at`.

### Endpoints Envolvidos (architecture.md Seção 3.2.2)

- `POST /api/v1/scraping/comments` -- 202 Accepted
  - Response: `{"run_id": "uuid", "status": "started", "posts_queued": 20}`

### Tabelas Envolvidas
- `posts` (SELECT -- buscar posts para coletar comentários)
- `comments` (UPSERT ON CONFLICT instagram_id)
- `scraping_runs` (UPDATE comments_scraped + UPDATE errors)

### Custo Apify (NFR-009)
- 1 actor run por post = 20 runs por ciclo completo (10 posts x 2 candidatos)
- `resultsLimit: 500` por post alinhado com NFR-004 (estimativa de ~500 comentários/post)
- Actor ID configurável: `APIFY_COMMENT_ACTOR_ID` (default: `"apify/instagram-comment-scraper"`)

### PRD References
- FR-002: Instagram Comment Scraping -- todos os comentários de cada post via instagram-comment-scraper
- CON-001: Scraping exclusivamente via Apify
- NFR-004: Escala -- até 500 comentários por post
- NFR-005: Error Resilience -- falha parcial preservada, processo continua
- NFR-009: Cost Efficiency -- actor runs controlados

---

## File List

| Arquivo | Acao |
|---------|------|
| `app/services/scraping.py` | Modificar -- adicionar `scrape_comments()` e `scrape_all_comments()` |
| `app/routers/scraping.py` | Modificar -- adicionar `POST /api/v1/scraping/comments` |
| `tests/test_scraping.py` | Modificar -- adicionar testes de comment scraping |

---

## Dev Notes

<!-- @dev: Espaço para anotar decisões durante implementação -->
<!-- O campo reply_count: verificar se Apify retorna count ou array de replies -- tratar ambos os casos -->
<!-- Para o endpoint /scraping/comments, a seleção de posts "elegíveis" pode ser simplificada para MVP: buscar todos os posts do candidato is_active -->
<!-- O raw_data do comentário é útil para debug -- inclui campos que podem ser relevantes futuramente (reply_to, mentions, etc.) -->
<!-- Considerar adicionar log de progresso: "scraping comments for post N of M" -->

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
