# Story 1.5: Serviço de Análise de Sentimento -- LLM Fallback

## Status: InProgress
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 5

---

## Description

Como estrategista de campanha, quero que comentários ambíguos (onde o VADER não tem certeza) sejam reclassificados por um LLM com prompt em português, para que os dados de sentimento reflitam a nuance linguística do português que o VADER pode perder.

Esta story adiciona o fallback LLM ao serviço de sentimento. O LLM processa apenas comentários na zona ambígua (compound entre -0.05 e 0.05, com texto > 20 caracteres), atualiza `llm_label`, `llm_confidence`, e `final_label` nos registros existentes de `sentiment_scores`, usando `httpx` para chamadas assíncronas configuráveis via env vars.

---

## Acceptance Criteria

- [x] **AC1**: Given um texto de comentário ambíguo em português, when `analyze_sentiment_llm(comment_text: str) -> LLMSentimentResult` é chamado, then uma requisição HTTP é enviada ao LLM configurado (`LLM_PROVIDER`, `LLM_MODEL`, `LLM_API_KEY`) com o prompt em português estruturado conforme `architecture.md` Seção 6.3, e o resultado é um `LLMSentimentResult` com `llm_label` (positive/negative/neutral), `llm_confidence` (0.0-1.0), e `llm_model` (nome do modelo usado).

- [x] **AC2**: Given que o prompt para o LLM está definido, when `analyze_sentiment_llm()` é chamado, then o prompt segue exatamente a estrutura:
  - System: `"Voce e um analista de sentimento para comentarios em portugues do Instagram. Classifique o comentario como 'positive', 'negative' ou 'neutral'. Responda APENAS em JSON: {\"label\": \"positive|negative|neutral\", \"confidence\": 0.0-1.0}"`
  - User: `f"Classifique o sentimento: \"{comment_text}\""`
  - `temperature: 0.1`, `max_tokens: 50`

- [x] **AC3**: Given que `reclassify_ambiguous_comments() -> int` é chamado, when executado, then: (a) seleciona todos os registros de `sentiment_scores` onde `vader_compound > -0.05 AND vader_compound < 0.05 AND llm_label IS NULL` (usando o index parcial `idx_sentiment_ambiguous`); (b) filtra adicionalmente por `len(comment_text) > LLM_AMBIGUOUS_MIN_LENGTH` (20 chars); (c) invoca `analyze_sentiment_llm()` para cada comentário elegível; (d) retorna o total de comentários reclassificados.

- [x] **AC4**: Given que o LLM retorna um resultado, when `reclassify_ambiguous_comments()` processa, then o registro em `sentiment_scores` é atualizado: (a) se `llm_confidence >= LLM_CONFIDENCE_THRESHOLD (0.7)`: `final_label = llm_label`; (b) se `llm_confidence < 0.7`: `final_label` permanece `vader_label`; (c) em ambos os casos: `llm_label`, `llm_confidence`, e `llm_model` são persistidos.

- [x] **AC5**: Given que a chamada à API do LLM falha (timeout, HTTP error, JSON inválido), when a exceção é capturada para um comentário específico, then: (a) o erro é logado com `comment_id`, `error_type`, `error_message`; (b) o registro de `sentiment_scores` NÃO é modificado (preserva `vader_label` como `final_label`); (c) o processamento continua para o próximo comentário; (d) o contador de reclassificados não incrementa para comentários com falha.

- [x] **AC6**: Given que `POST /api/v1/analysis/sentiment/llm-fallback` é chamado, when processado, then: (a) `reclassify_ambiguous_comments()` é invocado; (b) a resposta `200 OK` é retornada com:
  ```json
  {
    "reclassified_count": 47,
    "api_calls_made": 47,
    "confidence_upgrades": 32,
    "retained_vader_label": 15
  }
  ```
  Os campos `confidence_upgrades` (quantos tiveram `final_label` atualizado para LLM) e `retained_vader_label` (quantos mantiveram `vader_label`) devem ser calculados durante o processamento.

- [x] **AC7**: Given que o número de chamadas à API é logado por run (NFR-009 + CON-009), when `reclassify_ambiguous_comments()` completa, then uma mensagem de log structured com `api_calls_made`, `reclassified_count`, `cost_estimate_usd` (calculado com base em `max_tokens * N * pricing`) é emitida em nível INFO.

- [x] **AC8**: Given que os unit tests existem em `tests/test_sentiment.py`, when `pytest tests/test_sentiment.py -k "llm"` é executado, then todos passam. Os testes cobrem:
  - `analyze_sentiment_llm()` com mock do `httpx` retornando JSON válido
  - Threshold de confiança: `confidence=0.8` → `final_label = llm_label`; `confidence=0.5` → `final_label = vader_label`
  - Falha da API do LLM: `sentiment_scores` não é alterado, erro logado, processamento continua
  - `reclassify_ambiguous_comments()`: filtragem correta (ambiguous zone + min length)

---

## Scope

### IN
- `app/services/sentiment.py` -- adicionar `analyze_sentiment_llm()` e `reclassify_ambiguous_comments()`
- Chamada HTTP assíncrona via `httpx` para API do LLM (OpenAI por padrão)
- UPDATE de `sentiment_scores` com campos LLM
- `app/routers/analysis.py` -- adicionar `POST /api/v1/analysis/sentiment/llm-fallback`
- `tests/test_sentiment.py` -- seção de testes LLM

### OUT
- Suporte a múltiplos provedores LLM (apenas OpenAI API format no MVP)
- Reclassificação de comentários com alta certeza do VADER (fora da zona ambígua)
- Análise de sentimento de posts/captions (apenas comentários)
- Rate limiting sofisticado (apenas try/except básico)

---

## Dependencies

- Story 1.1 concluída (configuração com `LLM_PROVIDER`, `LLM_MODEL`, `LLM_API_KEY`)
- Story 1.4 concluída (registros em `sentiment_scores` com `vader_compound` preenchido)
- `httpx` presente em `requirements.txt`

---

## Technical Notes

### httpx Async Pattern (architecture.md Seção 6.3)

```python
import httpx
from app.core.config import settings

async def analyze_sentiment_llm(comment_text: str) -> LLMSentimentResult:
    async with httpx.AsyncClient(timeout=10.0) as client:
        response = await client.post(
            "https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {settings.LLM_API_KEY}"},
            json={
                "model": settings.LLM_MODEL,
                "messages": [
                    {"role": "system", "content": SENTIMENT_SYSTEM_PROMPT},
                    {"role": "user", "content": f"Classifique o sentimento: \"{comment_text}\""}
                ],
                "temperature": 0.1,
                "max_tokens": 50
            }
        )
        response.raise_for_status()
        data = response.json()
        content = json.loads(data["choices"][0]["message"]["content"])
        return LLMSentimentResult(
            llm_label=content["label"],
            llm_confidence=content["confidence"],
            llm_model=settings.LLM_MODEL
        )
```

### Critério de Elegibilidade para LLM (architecture.md Seção 4.2)

```
-0.05 < vader_compound < 0.05  AND  len(text) > 20  AND  llm_label IS NULL
```

O index parcial `idx_sentiment_ambiguous` no Supabase cobre essa query eficientemente (SCHEMA.md Seção 4).

### Query para Comentários Ambíguos (SCHEMA.md função `get_ambiguous_comments`)

```python
result = supabase.rpc("get_ambiguous_comments", {"limit_val": 500}).execute()
```

A função PL/pgSQL já está definida nas migrations -- retorna `comment_id`, `text`, `vader_compound`.

### UPDATE de sentiment_scores

```python
supabase.table("sentiment_scores").update({
    "llm_label": llm_result.llm_label,
    "llm_confidence": llm_result.llm_confidence,
    "llm_model": llm_result.llm_model,
    "final_label": final_label,  # llm_label se confidence >= 0.7, else vader_label
    "updated_at": datetime.utcnow().isoformat()
}).eq("comment_id", str(comment_id)).execute()
```

### Endpoints Envolvidos (architecture.md Seção 3.2.3)

- `POST /api/v1/analysis/sentiment/llm-fallback`
  - Response: `{"reclassified_count": 47, "api_calls_made": 47, "confidence_upgrades": 32, "retained_vader_label": 15}`

### Tabelas Envolvidas
- `sentiment_scores` (SELECT ambiguous + UPDATE com LLM results)
- `comments` (JOIN para obter text e verificar len)

### PRD References
- FR-004: LLM Fallback Sentiment Analysis -- critérios exatos de elegibilidade
- NFR-003: Portuguese Language Support -- prompt obrigatoriamente em português
- CON-008: LLM Provider configurável via env vars
- CON-009: Budget -- LLM apenas para subset ambíguo, log de API calls

### Considerações de Custo (CON-009)

- GPT-4o-mini pricing (fev/2026): ~$0.00015/1K input tokens, ~$0.0006/1K output tokens
- Por comentário: ~30 tokens input + 20 tokens output = ~$0.000014/comentário
- Para 1.500 comentários ambíguos (15% de 10K): ~$0.02/ciclo
- Log de `cost_estimate_usd` ajuda monitoramento

---

## Risks

| Risco | Probabilidade | Impacto | Mitigacao |
|-------|--------------|---------|-----------|
| API do LLM indisponivel (timeout, rate limit, outage) | Media | Medio | AC5 define fallback: erro logado, vader_label mantido como final_label, processamento continua para proximo comentario |
| Custo de API acima do esperado com volume inesperado de ambiguos | Baixa | Medio | Estimativa de ~15% ambiguos (~$0.02/ciclo para 10K comentarios); AC7 loga cost_estimate_usd para monitoramento; CON-009 respeitado |
| LLM retorna JSON invalido ou labels fora do enum | Media | Baixo | AC5 trata json.JSONDecodeError como falha de API; vader_label preservado; nenhuma corrupcao de dados |
| LLM confidence sistematicamente abaixo de 0.7, tornando fallback inutil | Baixa | Medio | Se ocorrer, final_label mantem vader_label (comportamento seguro); ajuste de threshold pode ser feito sem mudanca de schema |
| Race condition entre VADER batch (Story 1.4) e LLM fallback rodando simultaneamente | Baixa | Alto | Endpoints sao triggers manuais separados; pipeline full (Story 1.7) executa sequencialmente com lock |

---

## File List

| Arquivo | Acao | Status |
|---------|------|--------|
| `app/services/sentiment.py` | Modificar -- adicionar `analyze_sentiment_llm()`, `_get_ambiguous_comments()`, `reclassify_ambiguous_comments()` | Done |
| `app/routers/analysis.py` | Modificar -- adicionar `POST /analysis/sentiment/llm-fallback` | Done |
| `tests/test_sentiment.py` | Modificar -- adicionar testes LLM (2 LLM call, 2 confidence, 2 failure, 1 filtering, 1 endpoint) | Done |

---

## Dev Notes

- [AUTO-DECISION] analyze_sentiment_llm() e reclassify_ambiguous_comments() sao async nativos; endpoint POST /llm-fallback usa await diretamente
- [AUTO-DECISION] Usou SDK queries (.gt(), .lt(), .is_()) ao inves de RPC function get_ambiguous_comments() para nao depender de migrations
- [AUTO-DECISION] Label validation: se LLM retorna label fora do enum (positive/negative/neutral), fallback para "neutral"
- [AUTO-DECISION] Confidence clamp: valores fora de [0.0, 1.0] sao clampados para prevenir corrupcao
- [AUTO-DECISION] Cost estimate usa pricing do GPT-4o-mini de fev/2026 (~$0.00015/1K input + $0.0006/1K output)
- [AUTO-DECISION] Nenhum rate limiting adicionado (MVP, poucos comentarios ambiguos por ciclo)

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
| 2026-02-21 | Pax (PO) | Validacao: GO 9/10. Adicionada secao Risks (unica falha). Status Draft -> Ready |
| 2026-02-21 | Dex (Dev) | Implementacao completa. Todos 8 ACs atendidos. 8 testes LLM passando (2 LLM call + 2 confidence + 2 failure + 1 filter + 1 endpoint). Status Ready -> InProgress |

---

## Validation

| Item | Criterio | Resultado |
|------|----------|-----------|
| 1 | Titulo claro e objetivo | PASS |
| 2 | Descricao completa | PASS |
| 3 | ACs testaveis (Given/When/Then) | PASS |
| 4 | Escopo bem definido (IN/OUT) | PASS |
| 5 | Dependencias mapeadas | PASS |
| 6 | Estimativa de complexidade | PASS |
| 7 | Valor de negocio | PASS |
| 8 | Riscos documentados | PASS (adicionado durante validacao) |
| 9 | Criterios de Done | PASS |
| 10 | Alinhamento com PRD/Epic | PASS |

**Score: 9/10**
**Verdict: GO**
**Validated by: Pax (PO) -- 2026-02-21**
**Confidence: High**

### Anti-Hallucination Verification
- PRD FR-004 eligibility criteria (-0.05 < score < 0.05, text > 20 chars): Verified, exact match
- PRD CON-008 LLM provider configurable via env vars: Verified in story description and AC1
- PRD CON-009 budget control (LLM only for ambiguous subset): Verified in AC7 cost logging
- SCHEMA.md Section 3.5 columns (llm_label, llm_confidence, llm_model, final_label): Verified present
- SCHEMA.md Section 4 partial index idx_sentiment_ambiguous: Verified, referenced correctly in AC3
- Architecture.md Section 6.3 prompt structure: Verified, AC2 matches exactly
- Architecture.md Section 4.2 confidence threshold (>= 0.7): Verified, AC4 matches

### Notes
- Recurring pattern: River (SM) stories consistently missing Risks section. Added during validation.
- Story quality is high across all other 9 criteria.
- This story correctly builds on Story 1.4 (modifies files created there, not creates new ones).
