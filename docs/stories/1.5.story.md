# Story 1.5: Serviço de Análise de Sentimento -- LLM Fallback

## Status: Draft
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 5

---

## Description

Como estrategista de campanha, quero que comentários ambíguos (onde o VADER não tem certeza) sejam reclassificados por um LLM com prompt em português, para que os dados de sentimento reflitam a nuance linguística do português que o VADER pode perder.

Esta story adiciona o fallback LLM ao serviço de sentimento. O LLM processa apenas comentários na zona ambígua (compound entre -0.05 e 0.05, com texto > 20 caracteres), atualiza `llm_label`, `llm_confidence`, e `final_label` nos registros existentes de `sentiment_scores`, usando `httpx` para chamadas assíncronas configuráveis via env vars.

---

## Acceptance Criteria

- [ ] **AC1**: Given um texto de comentário ambíguo em português, when `analyze_sentiment_llm(comment_text: str) -> LLMSentimentResult` é chamado, then uma requisição HTTP é enviada ao LLM configurado (`LLM_PROVIDER`, `LLM_MODEL`, `LLM_API_KEY`) com o prompt em português estruturado conforme `architecture.md` Seção 6.3, e o resultado é um `LLMSentimentResult` com `llm_label` (positive/negative/neutral), `llm_confidence` (0.0-1.0), e `llm_model` (nome do modelo usado).

- [ ] **AC2**: Given que o prompt para o LLM está definido, when `analyze_sentiment_llm()` é chamado, then o prompt segue exatamente a estrutura:
  - System: `"Voce e um analista de sentimento para comentarios em portugues do Instagram. Classifique o comentario como 'positive', 'negative' ou 'neutral'. Responda APENAS em JSON: {\"label\": \"positive|negative|neutral\", \"confidence\": 0.0-1.0}"`
  - User: `f"Classifique o sentimento: \"{comment_text}\""`
  - `temperature: 0.1`, `max_tokens: 50`

- [ ] **AC3**: Given que `reclassify_ambiguous_comments() -> int` é chamado, when executado, then: (a) seleciona todos os registros de `sentiment_scores` onde `vader_compound > -0.05 AND vader_compound < 0.05 AND llm_label IS NULL` (usando o index parcial `idx_sentiment_ambiguous`); (b) filtra adicionalmente por `len(comment_text) > LLM_AMBIGUOUS_MIN_LENGTH` (20 chars); (c) invoca `analyze_sentiment_llm()` para cada comentário elegível; (d) retorna o total de comentários reclassificados.

- [ ] **AC4**: Given que o LLM retorna um resultado, when `reclassify_ambiguous_comments()` processa, then o registro em `sentiment_scores` é atualizado: (a) se `llm_confidence >= LLM_CONFIDENCE_THRESHOLD (0.7)`: `final_label = llm_label`; (b) se `llm_confidence < 0.7`: `final_label` permanece `vader_label`; (c) em ambos os casos: `llm_label`, `llm_confidence`, e `llm_model` são persistidos.

- [ ] **AC5**: Given que a chamada à API do LLM falha (timeout, HTTP error, JSON inválido), when a exceção é capturada para um comentário específico, then: (a) o erro é logado com `comment_id`, `error_type`, `error_message`; (b) o registro de `sentiment_scores` NÃO é modificado (preserva `vader_label` como `final_label`); (c) o processamento continua para o próximo comentário; (d) o contador de reclassificados não incrementa para comentários com falha.

- [ ] **AC6**: Given que `POST /api/v1/analysis/sentiment/llm-fallback` é chamado, when processado, then: (a) `reclassify_ambiguous_comments()` é invocado; (b) a resposta `200 OK` é retornada com:
  ```json
  {
    "reclassified_count": 47,
    "api_calls_made": 47,
    "confidence_upgrades": 32,
    "retained_vader_label": 15
  }
  ```
  Os campos `confidence_upgrades` (quantos tiveram `final_label` atualizado para LLM) e `retained_vader_label` (quantos mantiveram `vader_label`) devem ser calculados durante o processamento.

- [ ] **AC7**: Given que o número de chamadas à API é logado por run (NFR-009 + CON-009), when `reclassify_ambiguous_comments()` completa, then uma mensagem de log structured com `api_calls_made`, `reclassified_count`, `cost_estimate_usd` (calculado com base em `max_tokens * N * pricing`) é emitida em nível INFO.

- [ ] **AC8**: Given que os unit tests existem em `tests/test_sentiment.py`, when `pytest tests/test_sentiment.py -k "llm"` é executado, then todos passam. Os testes cobrem:
  - `analyze_sentiment_llm()` com mock do `httpx` retornando JSON válido
  - Threshold de confiança: `confidence=0.8` → `final_label = llm_label`; `confidence=0.5` → `final_label = vader_label`
  - Falha da API do LLM: `sentiment_scores` não é alterado, erro logado, processamento continua
  - `reclassify_ambiguous_comments()`: filtragem correta (ambiguous zone + min length)

---

## Scope

### IN
- `app/services/sentiment.py` -- adicionar `analyze_sentiment_llm()` e `reclassify_ambiguous_comments()`
- Chamada HTTP assíncrona via `httpx` para API do LLM (OpenAI por padrão)
- UPDATE de `sentiment_scores` com campos LLM
- `app/routers/analysis.py` -- adicionar `POST /api/v1/analysis/sentiment/llm-fallback`
- `tests/test_sentiment.py` -- seção de testes LLM

### OUT
- Suporte a múltiplos provedores LLM (apenas OpenAI API format no MVP)
- Reclassificação de comentários com alta certeza do VADER (fora da zona ambígua)
- Análise de sentimento de posts/captions (apenas comentários)
- Rate limiting sofisticado (apenas try/except básico)

---

## Dependencies

- Story 1.1 concluída (configuração com `LLM_PROVIDER`, `LLM_MODEL`, `LLM_API_KEY`)
- Story 1.4 concluída (registros em `sentiment_scores` com `vader_compound` preenchido)
- `httpx` presente em `requirements.txt`

---

## Technical Notes

### httpx Async Pattern (architecture.md Seção 6.3)

```python
import httpx
from app.core.config import settings

async def analyze_sentiment_llm(comment_text: str) -> LLMSentimentResult:
    async with httpx.AsyncClient(timeout=10.0) as client:
        response = await client.post(
            "https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {settings.LLM_API_KEY}"},
            json={
                "model": settings.LLM_MODEL,
                "messages": [
                    {"role": "system", "content": SENTIMENT_SYSTEM_PROMPT},
                    {"role": "user", "content": f"Classifique o sentimento: \"{comment_text}\""}
                ],
                "temperature": 0.1,
                "max_tokens": 50
            }
        )
        response.raise_for_status()
        data = response.json()
        content = json.loads(data["choices"][0]["message"]["content"])
        return LLMSentimentResult(
            llm_label=content["label"],
            llm_confidence=content["confidence"],
            llm_model=settings.LLM_MODEL
        )
```

### Critério de Elegibilidade para LLM (architecture.md Seção 4.2)

```
-0.05 < vader_compound < 0.05  AND  len(text) > 20  AND  llm_label IS NULL
```

O index parcial `idx_sentiment_ambiguous` no Supabase cobre essa query eficientemente (SCHEMA.md Seção 4).

### Query para Comentários Ambíguos (SCHEMA.md função `get_ambiguous_comments`)

```python
result = supabase.rpc("get_ambiguous_comments", {"limit_val": 500}).execute()
```

A função PL/pgSQL já está definida nas migrations -- retorna `comment_id`, `text`, `vader_compound`.

### UPDATE de sentiment_scores

```python
supabase.table("sentiment_scores").update({
    "llm_label": llm_result.llm_label,
    "llm_confidence": llm_result.llm_confidence,
    "llm_model": llm_result.llm_model,
    "final_label": final_label,  # llm_label se confidence >= 0.7, else vader_label
    "updated_at": datetime.utcnow().isoformat()
}).eq("comment_id", str(comment_id)).execute()
```

### Endpoints Envolvidos (architecture.md Seção 3.2.3)

- `POST /api/v1/analysis/sentiment/llm-fallback`
  - Response: `{"reclassified_count": 47, "api_calls_made": 47, "confidence_upgrades": 32, "retained_vader_label": 15}`

### Tabelas Envolvidas
- `sentiment_scores` (SELECT ambiguous + UPDATE com LLM results)
- `comments` (JOIN para obter text e verificar len)

### PRD References
- FR-004: LLM Fallback Sentiment Analysis -- critérios exatos de elegibilidade
- NFR-003: Portuguese Language Support -- prompt obrigatoriamente em português
- CON-008: LLM Provider configurável via env vars
- CON-009: Budget -- LLM apenas para subset ambíguo, log de API calls

### Considerações de Custo (CON-009)

- GPT-4o-mini pricing (fev/2026): ~$0.00015/1K input tokens, ~$0.0006/1K output tokens
- Por comentário: ~30 tokens input + 20 tokens output = ~$0.000014/comentário
- Para 1.500 comentários ambíguos (15% de 10K): ~$0.02/ciclo
- Log de `cost_estimate_usd` ajuda monitoramento

---

## File List

| Arquivo | Acao |
|---------|------|
| `app/services/sentiment.py` | Modificar -- adicionar `analyze_sentiment_llm()` e `reclassify_ambiguous_comments()` |
| `app/routers/analysis.py` | Modificar -- adicionar `POST /analysis/sentiment/llm-fallback` |
| `tests/test_sentiment.py` | Modificar -- adicionar testes LLM |

---

## Dev Notes

<!-- @dev: Espaço para anotar decisões durante implementação -->
<!-- analyze_sentiment_llm() deve ser async para usar httpx async -- o endpoint router também deve ser async -->
<!-- Se o FastAPI endpoint é sync, usar asyncio.run() ou tornar o endpoint async -->
<!-- O JSON retornado pelo LLM pode não ser válido -- tratar json.JSONDecodeError como falha de API -->
<!-- Para MVP, o rate limiting do OpenAI não deve ser problema (poucos comentários) -- mas adicionar sleep(0.1) entre calls se necessário -->
<!-- O campo llm_model no banco preserva qual modelo foi usado -- útil para rastreabilidade de custo -->

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
