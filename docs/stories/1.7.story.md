# Story 1.7: Scheduler para Scraping Periódico + Sugestões Estratégicas

## Status: Draft
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 8

---

## Description

Como coordenador de campanha, quero que o scraping execute automaticamente a cada 6 horas e que o sistema gere sugestões estratégicas via IA baseadas nos dados coletados, para que os dados estejam sempre atualizados sem intervenção manual e o time receba insights acionáveis.

Esta story integra APScheduler com FastAPI via lifespan, implementa o pipeline completo (posts → comentários → VADER → LLM fallback → temas), adiciona lock de concorrência para prevenir runs simultâneos, o endpoint de trigger manual, o endpoint de health check completo, o endpoint de sugestões estratégicas, e logging estruturado de todas as operações.

---

## Acceptance Criteria

- [ ] **AC1**: Given que a aplicação inicia, when o lifespan event de startup executa, then: (a) um `APScheduler BackgroundScheduler` é inicializado com `IntervalTrigger(hours=settings.SCRAPING_INTERVAL_HOURS)`; (b) o job `run_full_pipeline` é adicionado ao scheduler; (c) o scheduler inicia com `scheduler.start()`; (d) ao shutdown da aplicação, `scheduler.shutdown()` é chamado via lifespan cleanup. O scheduler é acessível globalmente via módulo `app/scheduler/jobs.py`.

- [ ] **AC2**: Given que o scheduler dispara `run_full_pipeline()`, when executado, then o pipeline completo é executado na seguinte sequência: (1) `scrape_posts()` para cada candidato ativo, (2) `scrape_all_comments()` para todos os posts coletados, (3) `analyze_comments_batch()` para comentários novos, (4) `reclassify_ambiguous_comments()` para comentários ambíguos, (5) `classify_all_unthemed_comments()` para comentários sem tema. Cada fase usa os serviços das Stories 1.2-1.6.

- [ ] **AC3**: Given que um `threading.Lock` existe em `app/scheduler/lock.py`, when `run_full_pipeline()` tenta adquirir o lock, then: (a) se o lock está livre, o lock é adquirido e o pipeline executa; (b) se o lock já está adquirido (run em progresso), a função loga um warning `"Pipeline already running, skipping scheduled trigger"` e retorna sem executar; (c) após o pipeline completar (sucesso ou erro), o lock é sempre liberado (via `finally`).

- [ ] **AC4**: Given que `POST /api/v1/scraping/run` é chamado, when processado, then: (a) verifica se o lock está adquirido; (b) se livre: inicia o pipeline em background (usando `BackgroundTasks` do FastAPI ou thread), retorna `202 Accepted` com `{"run_id": "<uuid>", "status": "started", "message": "Full pipeline initiated"}`; (c) se ocupado: retorna `409 Conflict` com `{"detail": "Pipeline already in progress", "current_run_id": "<uuid>"}`.

- [ ] **AC5**: Given que `GET /health` é chamado (endpoint completo da Story 1.1 agora com scheduler), when processado, then retorna `200 OK` com payload completo:
  ```json
  {
    "status": "ok",
    "database": "connected",
    "scheduler": "running",
    "last_scrape": "2026-02-21T14:00:00Z"
  }
  ```
  - `database`: resultado real de query no Supabase (tabela `candidates`)
  - `scheduler`: `"running"` se scheduler está ativo, `"stopped"` se não
  - `last_scrape`: timestamp do último `scraping_runs` com `status: "success"` (usando função `get_last_successful_scrape()`) ou `null` se nenhum
  - Se database está DOWN: retorna `503 Service Unavailable` com `{"status": "degraded", ...}`

- [ ] **AC6**: Given que `POST /api/v1/analytics/suggestions` é chamado com body opcional `{"candidate_id": "uuid"}`, when processado, then: (a) o serviço `app/services/suggestions.py` agrega o analytics summary atual (overview metrics + top themes + sentiment trends para ambos os candidatos); (b) envia o summary como JSON no prompt LLM (conforme `architecture.md` Seção 6.3); (c) parseia a resposta e retorna `200 OK` com lista de 3-5 sugestões estratégicas, cada uma com `title`, `description`, `supporting_data`, `priority`.

- [ ] **AC7**: Given que o LLM gera sugestões estratégicas, when a resposta é recebida e parseada, then: (a) as sugestões são persistidas na tabela `strategic_insights` com `scraping_run_id` do run mais recente, `candidate_id` (se especificado), `llm_model`, e `input_summary` (JSONB do contexto enviado); (b) a resposta inclui `generated_at` e `data_snapshot` com totais do dataset.

- [ ] **AC8**: Given que todas as operações do scheduler e pipeline são executadas, when qualquer fase inicia ou completa, then logs estruturados são emitidos com:
  - Pipeline start: `{"event": "pipeline_start", "run_id": "...", "trigger": "scheduler|manual"}`
  - Fase completa: `{"event": "phase_complete", "phase": "post_scraping|comment_scraping|vader|llm|themes", "count": N, "duration_ms": N}`
  - Pipeline completo: `{"event": "pipeline_complete", "run_id": "...", "posts_scraped": N, "comments_scraped": N, "duration_seconds": N.N}`
  - Pipeline erro: `{"event": "pipeline_error", "run_id": "...", "phase": "...", "error": "..."}`

- [ ] **AC9**: Given que o `ScrapingRun` é criado no início do pipeline, when o pipeline completa com sucesso, then: `status` → `"success"`, `completed_at` → timestamp atual, `duration_seconds` calculado. Se qualquer fase gera erros mas o pipeline não falha completamente: `status` → `"partial"`. Se o pipeline falha completamente: `status` → `"failed"`.

- [ ] **AC10**: Given que os unit tests existem em `tests/test_pipeline.py`, when `pytest tests/test_pipeline.py` é executado, then todos passam. Os testes cobrem:
  - Scheduler initialization: job adicionado, scheduler started
  - Concurrency lock: segunda chamada com lock adquirido retorna sem executar
  - Manual trigger: `POST /scraping/run` com e sem lock ativo
  - Health check: database connected + scheduler running (mockados)
  - Suggestions: mock do LLM retornando 3 sugestões válidas, persistidas em `strategic_insights`

---

## Scope

### IN
- `app/scheduler/jobs.py` -- `run_full_pipeline()`, APScheduler setup
- `app/scheduler/lock.py` -- `threading.Lock` singleton
- `app/services/suggestions.py` -- `generate_strategic_suggestions(candidate_id?)`
- `app/services/pipeline.py` -- orquestração do pipeline completo
- `app/routers/scraping.py` -- adicionar `POST /api/v1/scraping/run`
- `app/routers/suggestions.py` -- `POST /api/v1/analytics/suggestions`
- `app/routers/health.py` -- atualizar para incluir scheduler status e last_scrape real
- `app/main.py` -- lifespan com scheduler start/shutdown, registrar `suggestions.router`
- Persistência de `strategic_insights` em Supabase
- `tests/test_pipeline.py`

### OUT
- APScheduler persistente (usando `MemoryJobStore` -- jobs perdidos em restart, aceitável para MVP)
- Notificações externas (email, Slack) sobre status do pipeline
- Agendamento baseado em cron (apenas IntervalTrigger)
- Sugestões em múltiplos idiomas (apenas PT-BR)

---

## Dependencies

- Story 1.1 concluída (configuração, health endpoint base)
- Stories 1.2-1.6 concluídas (todos os serviços que o pipeline orquestra)
- `APScheduler` presente em `requirements.txt`
- Tabela `strategic_insights` no Supabase (migration 002)

---

## Technical Notes

### APScheduler com FastAPI Lifespan (architecture.md Seção 2.1 + 9.4)

```python
# app/main.py
from contextlib import asynccontextmanager
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger

scheduler = BackgroundScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    scheduler.add_job(
        run_full_pipeline,
        IntervalTrigger(hours=settings.SCRAPING_INTERVAL_HOURS),
        id="full_pipeline",
        replace_existing=True
    )
    scheduler.start()
    logger.info("scheduler_started", interval_hours=settings.SCRAPING_INTERVAL_HOURS)
    yield
    # Shutdown
    scheduler.shutdown(wait=False)
    logger.info("scheduler_stopped")

app = FastAPI(lifespan=lifespan)
```

### Lock de Concorrência (architecture.md Seção 9.4)

```python
# app/scheduler/lock.py
import threading
from uuid import UUID

_pipeline_lock = threading.Lock()
_current_run_id: UUID | None = None

def acquire_pipeline_lock(run_id: UUID) -> bool:
    global _current_run_id
    if _pipeline_lock.acquire(blocking=False):
        _current_run_id = run_id
        return True
    return False

def release_pipeline_lock():
    global _current_run_id
    _current_run_id = None
    try:
        _pipeline_lock.release()
    except RuntimeError:
        pass  # Already released

def get_current_run_id() -> UUID | None:
    return _current_run_id
```

### Prompt de Sugestões Estratégicas (architecture.md Seção 6.3)

```python
SUGGESTIONS_SYSTEM_PROMPT = (
    "Voce e um consultor estrategico de campanha politica. "
    "Analise os dados fornecidos e gere 3-5 sugestoes estrategicas acionaveis. "
    "Cada sugestao deve ter: titulo, descricao, dado de apoio especifico, e prioridade (high/medium/low). "
    "Responda APENAS em JSON com a estrutura: "
    "{\"suggestions\": [{\"title\": \"...\", \"description\": \"...\", \"supporting_data\": \"...\", \"priority\": \"high|medium|low\"}]}"
)
```

### Analytics Summary para o Prompt

O context enviado ao LLM deve ser compacto:
```python
analytics_summary = {
    "candidates": [overview_candidate_1, overview_candidate_2],
    "top_themes_by_candidate": {...},
    "sentiment_trends": {...}
}
```

### Endpoints Envolvidos (architecture.md Seções 3.2.2 + 3.2.5)

- `POST /api/v1/scraping/run` -- 202 ou 409
- `POST /api/v1/analytics/suggestions` -- 200 com lista de sugestões
- `GET /health` -- 200 ou 503

### Tabelas Envolvidas
- `scraping_runs` (INSERT, UPDATE status/completed_at/duration)
- `strategic_insights` (INSERT após geração de sugestões)
- `candidates` (health check query)
- Todas as tabelas via pipeline (indiretamente via serviços das stories anteriores)

### PRD References
- FR-012: Strategic Suggestions -- 3-5 sugestões com dados específicos de apoio
- FR-013: Automated Scheduling -- APScheduler, intervalo configurável, sem runs concorrentes
- FR-014: Manual Scraping Trigger -- endpoint POST /scraping/run, 409 se já em progresso
- FR-015: API Health Check -- status, database, scheduler, last_scrape
- NFR-002: Data Freshness -- schedule padrão 6h garante dados < 7h stale
- NFR-005: Error Resilience -- pipeline parcial preservado, lock liberado em finally
- NFR-008: Observability -- logging estruturado de todas as fases

---

## File List

| Arquivo | Acao |
|---------|------|
| `app/scheduler/jobs.py` | Criar -- `run_full_pipeline()` e APScheduler job |
| `app/scheduler/lock.py` | Criar -- threading.Lock singleton |
| `app/services/pipeline.py` | Criar -- orquestração das fases do pipeline |
| `app/services/suggestions.py` | Criar -- `generate_strategic_suggestions()` |
| `app/routers/suggestions.py` | Criar -- `POST /api/v1/analytics/suggestions` |
| `app/routers/scraping.py` | Modificar -- adicionar `POST /api/v1/scraping/run` |
| `app/routers/health.py` | Modificar -- health check completo com scheduler + last_scrape |
| `app/main.py` | Modificar -- lifespan, registrar suggestions.router |
| `tests/test_pipeline.py` | Criar |

---

## Dev Notes

<!-- @dev: Espaço para anotar decisões durante implementação -->
<!-- O pipeline DEVE ser executado em thread separada quando chamado via endpoint manual (não bloquear o request) -- usar BackgroundTasks do FastAPI ou threading.Thread -->
<!-- APScheduler BackgroundScheduler já executa jobs em threads separadas -- thread-safe para o scheduler trigger -->
<!-- O lock usa blocking=False para não bloquear -- se lock não adquirido, log warning e retornar -->
<!-- Para o endpoint POST /scraping/run: retornar 202 imediatamente, pipeline roda em background -->
<!-- Sugestões LLM: o prompt de analytics_summary não deve ultrapassar ~2000 tokens -- truncar se necessário -->
<!-- strategic_insights.scraping_run_id: pode ser NULL se o run mais recente ainda está em progresso -->
<!-- Verificar se APScheduler é compatible com uvicorn/asyncio -- usar BackgroundScheduler (threaded), NÃO AsyncIOScheduler -->

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
