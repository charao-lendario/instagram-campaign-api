# Story 1.7: Scheduler para Scraping Periódico + Sugestões Estratégicas

## Status: InProgress
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 8

---

## Description

Como coordenador de campanha, quero que o scraping execute automaticamente a cada 6 horas e que o sistema gere sugestões estratégicas via IA baseadas nos dados coletados, para que os dados estejam sempre atualizados sem intervenção manual e o time receba insights acionáveis.

Esta story integra APScheduler com FastAPI via lifespan, implementa o pipeline completo (posts → comentários → VADER → LLM fallback → temas), adiciona lock de concorrência para prevenir runs simultâneos, o endpoint de trigger manual, o endpoint de health check completo, o endpoint de sugestões estratégicas, e logging estruturado de todas as operações.

---

## Acceptance Criteria

- [x] **AC1**: Given que a aplicação inicia, when o lifespan event de startup executa, then: (a) um `APScheduler BackgroundScheduler` é inicializado com `IntervalTrigger(hours=settings.SCRAPING_INTERVAL_HOURS)`; (b) o job `run_full_pipeline` é adicionado ao scheduler; (c) o scheduler inicia com `scheduler.start()`; (d) ao shutdown da aplicação, `scheduler.shutdown()` é chamado via lifespan cleanup. O scheduler é acessível globalmente via módulo `app/scheduler/jobs.py`.

- [x] **AC2**: Given que o scheduler dispara `run_full_pipeline()`, when executado, then o pipeline completo é executado na seguinte sequência: (1) `scrape_posts()` para cada candidato ativo, (2) `scrape_all_comments()` para todos os posts coletados, (3) `analyze_comments_batch()` para comentários novos, (4) `reclassify_ambiguous_comments()` para comentários ambíguos, (5) `classify_all_unthemed_comments()` para comentários sem tema. Cada fase usa os serviços das Stories 1.2-1.6.

- [x] **AC3**: Given que um `threading.Lock` existe em `app/scheduler/lock.py`, when `run_full_pipeline()` tenta adquirir o lock, then: (a) se o lock está livre, o lock é adquirido e o pipeline executa; (b) se o lock já está adquirido (run em progresso), a função loga um warning `"Pipeline already running, skipping scheduled trigger"` e retorna sem executar; (c) após o pipeline completar (sucesso ou erro), o lock é sempre liberado (via `finally`).

- [x] **AC4**: Given que `POST /api/v1/scraping/run` é chamado, when processado, then: (a) verifica se o lock está adquirido; (b) se livre: inicia o pipeline em background (usando `BackgroundTasks` do FastAPI ou thread), retorna `202 Accepted` com `{"run_id": "<uuid>", "status": "started", "message": "Full pipeline initiated"}`; (c) se ocupado: retorna `409 Conflict` com `{"detail": "Pipeline already in progress", "current_run_id": "<uuid>"}`.

- [x] **AC5**: Given que `GET /health` é chamado (endpoint completo da Story 1.1 agora com scheduler), when processado, then retorna `200 OK` com payload completo:
  ```json
  {
    "status": "ok",
    "database": "connected",
    "scheduler": "running",
    "last_scrape": "2026-02-21T14:00:00Z"
  }
  ```
  - `database`: resultado real de query no Supabase (tabela `candidates`)
  - `scheduler`: `"running"` se scheduler está ativo, `"stopped"` se não
  - `last_scrape`: timestamp do último `scraping_runs` com `status: "success"` (usando função `get_last_successful_scrape()`) ou `null` se nenhum
  - Se database está DOWN: retorna `503 Service Unavailable` com `{"status": "degraded", ...}`

- [x] **AC6**: Given que `POST /api/v1/analytics/suggestions` é chamado com body opcional `{"candidate_id": "uuid"}`, when processado, then: (a) o serviço `app/services/suggestions.py` agrega o analytics summary atual (overview metrics + top themes + sentiment trends para ambos os candidatos); (b) envia o summary como JSON no prompt LLM (conforme `architecture.md` Seção 6.3); (c) parseia a resposta e retorna `200 OK` com lista de 3-5 sugestões estratégicas, cada uma com `title`, `description`, `supporting_data`, `priority`.

- [x] **AC7**: Given que o LLM gera sugestões estratégicas, when a resposta é recebida e parseada, then: (a) as sugestões são persistidas na tabela `strategic_insights` com `scraping_run_id` do run mais recente, `candidate_id` (se especificado), `llm_model`, e `input_summary` (JSONB do contexto enviado); (b) a resposta inclui `generated_at` e `data_snapshot` com totais do dataset.

- [x] **AC8**: Given que todas as operações do scheduler e pipeline são executadas, when qualquer fase inicia ou completa, then logs estruturados são emitidos com:
  - Pipeline start: `{"event": "pipeline_start", "run_id": "...", "trigger": "scheduler|manual"}`
  - Fase completa: `{"event": "phase_complete", "phase": "post_scraping|comment_scraping|vader|llm|themes", "count": N, "duration_ms": N}`
  - Pipeline completo: `{"event": "pipeline_complete", "run_id": "...", "posts_scraped": N, "comments_scraped": N, "duration_seconds": N.N}`
  - Pipeline erro: `{"event": "pipeline_error", "run_id": "...", "phase": "...", "error": "..."}`

- [x] **AC9**: Given que o `ScrapingRun` é criado no início do pipeline, when o pipeline completa com sucesso, then: `status` → `"success"`, `completed_at` → timestamp atual, `duration_seconds` calculado. Se qualquer fase gera erros mas o pipeline não falha completamente: `status` → `"partial"`. Se o pipeline falha completamente: `status` → `"failed"`.

- [x] **AC10**: Given que os unit tests existem em `tests/test_pipeline.py`, when `pytest tests/test_pipeline.py` é executado, then todos passam. Os testes cobrem:
  - Scheduler initialization: job adicionado, scheduler started
  - Concurrency lock: segunda chamada com lock adquirido retorna sem executar
  - Manual trigger: `POST /scraping/run` com e sem lock ativo
  - Health check: database connected + scheduler running (mockados)
  - Suggestions: mock do LLM retornando 3 sugestões válidas, persistidas em `strategic_insights`

---

## Scope

### IN
- `app/scheduler/jobs.py` -- `run_full_pipeline()`, APScheduler setup
- `app/scheduler/lock.py` -- `threading.Lock` singleton
- `app/services/suggestions.py` -- `generate_strategic_suggestions(candidate_id?)`
- `app/services/pipeline.py` -- orquestração do pipeline completo
- `app/routers/scraping.py` -- adicionar `POST /api/v1/scraping/run`
- `app/routers/suggestions.py` -- `POST /api/v1/analytics/suggestions`
- `app/routers/health.py` -- atualizar para incluir scheduler status e last_scrape real
- `app/main.py` -- lifespan com scheduler start/shutdown, registrar `suggestions.router`
- Persistência de `strategic_insights` em Supabase
- `tests/test_pipeline.py`

### OUT
- APScheduler persistente (usando `MemoryJobStore` -- jobs perdidos em restart, aceitável para MVP)
- Notificações externas (email, Slack) sobre status do pipeline
- Agendamento baseado em cron (apenas IntervalTrigger)
- Sugestões em múltiplos idiomas (apenas PT-BR)

---

## Dependencies

- Story 1.1 concluída (configuração, health endpoint base)
- Stories 1.2-1.6 concluídas (todos os serviços que o pipeline orquestra)
- `APScheduler` presente em `requirements.txt`
- Tabela `strategic_insights` no Supabase (migration 002)

---

## Technical Notes

### APScheduler com FastAPI Lifespan (architecture.md Seção 2.1 + 9.4)

```python
# app/main.py
from contextlib import asynccontextmanager
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger

scheduler = BackgroundScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    scheduler.add_job(
        run_full_pipeline,
        IntervalTrigger(hours=settings.SCRAPING_INTERVAL_HOURS),
        id="full_pipeline",
        replace_existing=True
    )
    scheduler.start()
    logger.info("scheduler_started", interval_hours=settings.SCRAPING_INTERVAL_HOURS)
    yield
    # Shutdown
    scheduler.shutdown(wait=False)
    logger.info("scheduler_stopped")

app = FastAPI(lifespan=lifespan)
```

### Lock de Concorrência (architecture.md Seção 9.4)

```python
# app/scheduler/lock.py
import threading
from uuid import UUID

_pipeline_lock = threading.Lock()
_current_run_id: UUID | None = None

def acquire_pipeline_lock(run_id: UUID) -> bool:
    global _current_run_id
    if _pipeline_lock.acquire(blocking=False):
        _current_run_id = run_id
        return True
    return False

def release_pipeline_lock():
    global _current_run_id
    _current_run_id = None
    try:
        _pipeline_lock.release()
    except RuntimeError:
        pass  # Already released

def get_current_run_id() -> UUID | None:
    return _current_run_id
```

### Prompt de Sugestões Estratégicas (architecture.md Seção 6.3)

```python
SUGGESTIONS_SYSTEM_PROMPT = (
    "Voce e um consultor estrategico de campanha politica. "
    "Analise os dados fornecidos e gere 3-5 sugestoes estrategicas acionaveis. "
    "Cada sugestao deve ter: titulo, descricao, dado de apoio especifico, e prioridade (high/medium/low). "
    "Responda APENAS em JSON com a estrutura: "
    "{\"suggestions\": [{\"title\": \"...\", \"description\": \"...\", \"supporting_data\": \"...\", \"priority\": \"high|medium|low\"}]}"
)
```

### Analytics Summary para o Prompt

O context enviado ao LLM deve ser compacto:
```python
analytics_summary = {
    "candidates": [overview_candidate_1, overview_candidate_2],
    "top_themes_by_candidate": {...},
    "sentiment_trends": {...}
}
```

### Endpoints Envolvidos (architecture.md Seções 3.2.2 + 3.2.5)

- `POST /api/v1/scraping/run` -- 202 ou 409
- `POST /api/v1/analytics/suggestions` -- 200 com lista de sugestões
- `GET /health` -- 200 ou 503

### Tabelas Envolvidas
- `scraping_runs` (INSERT, UPDATE status/completed_at/duration)
- `strategic_insights` (INSERT após geração de sugestões)
- `candidates` (health check query)
- Todas as tabelas via pipeline (indiretamente via serviços das stories anteriores)

### PRD References
- FR-012: Strategic Suggestions -- 3-5 sugestões com dados específicos de apoio
- FR-013: Automated Scheduling -- APScheduler, intervalo configurável, sem runs concorrentes
- FR-014: Manual Scraping Trigger -- endpoint POST /scraping/run, 409 se já em progresso
- FR-015: API Health Check -- status, database, scheduler, last_scrape
- NFR-002: Data Freshness -- schedule padrão 6h garante dados < 7h stale
- NFR-005: Error Resilience -- pipeline parcial preservado, lock liberado em finally
- NFR-008: Observability -- logging estruturado de todas as fases

---

## Risks

| Risco | Probabilidade | Impacto | Mitigacao |
|-------|---------------|---------|-----------|
| APScheduler incompativel com uvicorn/asyncio event loop | Baixa | Alto | Usar BackgroundScheduler (threaded), NAO AsyncIOScheduler; ja documentado em Dev Notes |
| Lock de concorrencia nao liberado apos crash inesperado | Media | Alto | Lock liberado em bloco finally; restart da aplicacao reinicializa o lock automaticamente |
| LLM retorna JSON mal-formado nas sugestoes estrategicas | Media | Medio | Implementar parsing robusto com fallback; logar resposta raw em caso de falha; retornar erro 500 gracefully |
| Pipeline parcial deixa dados inconsistentes (posts sem comentarios, comentarios sem sentimento) | Baixa | Medio | Pipeline sequencial garante ordem; status "partial" registrado; proxima execucao completa dados pendentes |
| Custo de LLM para sugestoes estrategicas excede budget | Baixa | Baixo | GPT-4o-mini e o modelo mais barato; prompt limitado a ~2000 tokens; sugestoes geradas sob demanda, nao automaticamente |
| Job perdido em restart do servico (MemoryJobStore) | Media | Baixo | Aceitavel para MVP; scheduler reinicializa no startup; proxima execucao ocorre dentro do intervalo configurado |

---

## File List

| Arquivo | Acao | Status |
|---------|------|--------|
| `app/scheduler/__init__.py` | Criar -- package init | Done |
| `app/scheduler/jobs.py` | Criar -- BackgroundScheduler + IntervalTrigger + start/shutdown | Done |
| `app/scheduler/lock.py` | Criar -- threading.Lock singleton com acquire/release/status | Done |
| `app/services/pipeline.py` | Criar -- orquestração 5-phase pipeline com ScrapingRun tracking | Done |
| `app/services/suggestions.py` | Criar -- LLM strategic suggestions via httpx + persist em strategic_insights | Done |
| `app/routers/suggestions.py` | Criar -- `POST /api/v1/analytics/suggestions` | Done |
| `app/routers/scraping.py` | Modificar -- adicionar `POST /api/v1/scraping/run` (202/409) | Done |
| `app/routers/health.py` | Modificar -- scheduler status, last_scrape via RPC, 503 quando DB down | Done |
| `app/main.py` | Modificar -- lifespan com start/shutdown_scheduler, registrar analytics + suggestions routers | Done |
| `tests/test_pipeline.py` | Criar -- 13 testes (scheduler, lock, trigger, health, suggestions, pipeline) | Done |
| `tests/test_config.py` | Modificar -- atualizar health tests para 503 + rpc mock | Done |

---

## Dev Notes

- **[AUTO-DECISION] Threading vs BackgroundTasks**: Usado `threading.Thread` para o endpoint `POST /scraping/run` em vez de FastAPI `BackgroundTasks` porque o pipeline é síncrono e de longa duração. Thread daemon=True para não bloquear shutdown.
- **[AUTO-DECISION] Scheduler package**: Criado `app/scheduler/` como package separado (com `__init__.py`) em vez de um único arquivo, para separar responsabilidades de lock e jobs.
- **APScheduler compatibility**: Usado `BackgroundScheduler` (threaded), confirmado compatível com uvicorn/asyncio. `AsyncIOScheduler` causaria conflito com o event loop do FastAPI.
- **Lock implementation**: `threading.Lock` com `acquire(blocking=False)`. Release em `try/except RuntimeError` para idempotência. `_current_run_id` global para tracking do run ativo.
- **Pipeline async/sync boundary**: `reclassify_ambiguous_comments()` é async (usa httpx). Pipeline usa `asyncio.run()` com fallback para `asyncio.get_event_loop().run_until_complete()` quando já existe um event loop (caso do APScheduler executando em thread).
- **Suggestions LLM**: Usa httpx async direto para OpenAI API em vez de openai SDK para minimizar dependências. Parsing robusto com fallback para markdown code blocks (```json...```).
- **Suggestions persistence**: `_persist_suggestions()` usa upsert na tabela `strategic_insights` com `scraping_run_id` do run mais recente (query `scraping_runs` ordenado por `started_at DESC`).
- **Health endpoint breaking change**: Health agora retorna 503 quando DB está down (era 200 com "disconnected"). Testes pré-existentes em `test_config.py` atualizados para refletir novo comportamento.
- **Pipeline ScrapingRun tracking**: `_create_scraping_run()` insere registro em `scraping_runs`. Status final: "success" (tudo ok), "partial" (erros não-fatais), "failed" (exceção não capturada).

---

## Validation

| # | Criterio | Resultado |
|---|----------|-----------|
| 1 | Titulo claro e objetivo | PASS |
| 2 | Descricao completa (problema/necessidade) | PASS |
| 3 | Criterios de aceitacao testaveis (Given/When/Then) | PASS |
| 4 | Escopo bem definido (IN e OUT) | PASS |
| 5 | Dependencias mapeadas | PASS |
| 6 | Estimativa de complexidade | PASS |
| 7 | Valor de negocio claro | PASS |
| 8 | Riscos documentados | PASS (adicionado durante validacao) |
| 9 | Criterios de Done claros | PASS |
| 10 | Alinhamento com PRD/Epic | PASS |

**Score: 9/10 -> GO**
**Validado por:** Pax (PO) em 2026-02-21
**Nota:** Secao de Riscos ausente na criacao, adicionada durante validacao.

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
| 2026-02-21 | Pax (PO) | Validacao: GO 9/10. Adicionada secao Risks. Status Draft -> Ready |
| 2026-02-21 | Dex (Dev) | Status Ready -> InProgress. Implementacao completa: scheduler (jobs.py, lock.py), pipeline.py, suggestions.py, routers (suggestions.py, scraping.py update, health.py update), main.py lifespan, test_pipeline.py. Todos ACs marcados [x]. 13 testes novos passando. |
