# Story 1.6: Endpoints de Analytics e Comparação

## Status: Draft
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 8

---

## Description

Como estrategista de campanha, quero endpoints de API que agreguem e comparem dados de engajamento e sentimento entre candidatos e posts, para que o dashboard frontend possa renderizar todas as visualizações necessárias sem lógica de agregação no cliente.

Esta story implementa todos os endpoints do grupo `/api/v1/analytics/`, o serviço de extração de temas via keyword matching, e o serviço de analytics que agrega queries do Supabase. É a story de maior escopo do Epic 1 -- cobre 6 endpoints distintos e 2 serviços novos.

---

## Acceptance Criteria

- [ ] **AC1**: Given que `GET /api/v1/analytics/overview` é chamado sem parâmetros, when processado, then retorna `200 OK` com a estrutura exata definida em `architecture.md` Seção 3.2.4 (campo `candidates` com array de métricas por candidato, `last_scrape`, `total_comments_analyzed`). Para cada candidato: `total_posts`, `total_comments`, `average_sentiment_score`, `sentiment_distribution` (positive/negative/neutral counts), `total_engagement` (sum likes + comment_counts de todos os posts).

- [ ] **AC2**: Given que `GET /api/v1/analytics/sentiment-timeline` é chamado com parâmetros opcionais `candidate_id`, `start_date`, `end_date`, when processado, then retorna `200 OK` com lista de `data_points`, cada um contendo: `candidate_id`, `candidate_username`, `post_id`, `post_url`, `post_caption` (truncada em 100 chars), `posted_at`, `average_sentiment_score` (média do `vader_compound` dos comentários do post), `comment_count`. Quando `candidate_id` é omitido, retorna dados de ambos os candidatos. Quando datas são omitidas, padrão é últimos 30 dias.

- [ ] **AC3**: Given que `GET /api/v1/analytics/wordcloud` é chamado com `candidate_id` opcional, when processado, then retorna `200 OK` com lista de `{word, count}` pairs, excluindo stop words em português definidas em `app/core/constants.py`. As palavras são extraídas de todos os `comments.text` do candidato (ou de ambos se `candidate_id` omitido), tokenizadas, lowercased, e contadas. Retornar no máximo 200 palavras ordenadas por count decrescente.

- [ ] **AC4**: Given que `GET /api/v1/analytics/themes` é chamado com `candidate_id` opcional, when processado, then retorna `200 OK` com lista de objetos `{theme, count, percentage, by_candidate}`. O campo `by_candidate` contém contagens separadas por candidato. Percentagem calculada sobre o total de atribuições de tema. Fonte de dados: tabela `themes`.

- [ ] **AC5**: Given que `GET /api/v1/analytics/posts` é chamado com parâmetros opcionais `candidate_id`, `sort_by`, `order`, `limit`, `offset`, when processado, then retorna `200 OK` com lista de posts com métricas calculadas: `post_id`, `candidate_username`, `url`, `caption` (truncada em 150 chars), `posted_at`, `like_count`, `comment_count`, `positive_ratio` (positive_count / total_comments), `negative_ratio`, `average_sentiment_score`. Suporta `sort_by` em qualquer das métricas numéricas e `order` asc/desc. Inclui `total`, `limit`, `offset` para paginação.

- [ ] **AC6**: Given que `GET /api/v1/analytics/comparison` é chamado sem parâmetros, when processado, then retorna `200 OK` com array de 2 candidatos, cada um com: todos os campos de overview + `top_themes` (3 temas mais frequentes) + `trend` (`direction`, `recent_avg`, `previous_avg`, `delta`). O `trend` é calculado comparando a média de sentimento dos últimos 5 posts vs os 5 posts anteriores. `direction`: `"improving"` se delta > 0.02, `"declining"` se delta < -0.02, `"stable"` caso contrário.

- [ ] **AC7**: Given que o serviço de extração de temas existe em `app/services/themes.py`, when `classify_comment_themes(comment_text: str) -> list[ThemeCreate]` é chamado, then: (a) o texto é lowercased e normalizado (sem acentos para matching); (b) cada keyword da lista `THEME_KEYWORDS` é verificada contra o texto; (c) um `ThemeCreate` com `method: "keyword"` e `confidence: 1.0` é criado para cada tema com match; (d) se nenhum match, retorna `[ThemeCreate(theme="outros", confidence=0.5, method="keyword")]`.

- [ ] **AC8**: Given que `classify_all_unthemed_comments() -> int` existe em `app/services/themes.py`, when chamado, then: (a) busca todos os `comment_id` que não têm registro em `themes`; (b) para cada um, obtém o `text` e invoca `classify_comment_themes()`; (c) insere os `Theme` records no Supabase usando upsert com constraint `(comment_id, theme, method)`; (d) retorna o total de comentários processados.

- [ ] **AC9**: Given que todos os endpoints de analytics são chamados com dados existentes, when processados, then respondem em menos de 2 segundos (NFR-001). Os endpoints que fazem queries complexas devem usar as funções PL/pgSQL definidas nas migrations (ex: `get_candidate_overview`, `get_sentiment_timeline`, `get_theme_distribution`, `get_post_rankings`) quando disponíveis.

- [ ] **AC10**: Given que os unit tests existem em `tests/test_analytics.py`, when `pytest tests/test_analytics.py` é executado, then todos passam. Os testes cobrem: cada endpoint retorna a estrutura correta com dados mockados, comportamento com dados ausentes (candidato sem posts retorna zeros, não 404), e classificação de temas (keyword match, sem match → "outros").

---

## Scope

### IN
- `app/services/analytics.py` -- queries de agregação para cada endpoint
- `app/services/themes.py` -- `classify_comment_themes()`, `classify_all_unthemed_comments()`
- `app/routers/analytics.py` -- 6 endpoints GET de analytics
- Modelos de resposta em `app/models/analytics.py` (já definidos em Story 1.1, validar completude)
- `tests/test_analytics.py`
- `tests/test_themes.py`

### OUT
- Endpoint de suggestions (Story 1.7)
- LLM enrichment de temas ambíguos (além de keyword matching -- fora do MVP scope de temas)
- Dados em tempo real / WebSocket
- Cache de resultados de analytics

---

## Dependencies

- Story 1.1 concluída (modelos de analytics, cliente Supabase, constantes)
- Stories 1.2 + 1.3 concluídas (posts e comentários existem)
- Stories 1.4 + 1.5 concluídas (sentiment_scores preenchidos)
- Migrations `004_create_functions.sql` aplicadas no Supabase (funções PL/pgSQL)

---

## Technical Notes

### Funções PL/pgSQL Disponíveis (SCHEMA.md Seção 5)

Usar via `supabase.rpc()` para performance:

| Função | Endpoint que usa |
|--------|-----------------|
| `get_candidate_overview(candidate_id UUID)` | GET /analytics/overview |
| `get_sentiment_timeline(candidate_id, start, end)` | GET /analytics/sentiment-timeline |
| `get_theme_distribution(candidate_id)` | GET /analytics/themes |
| `get_post_rankings(candidate_id, sort_by, order, limit, offset)` | GET /analytics/posts |
| `get_comments_text_for_wordcloud(candidate_id, limit)` | GET /analytics/wordcloud |
| `get_candidate_comparison()` | GET /analytics/comparison |
| `get_last_successful_scrape()` | GET /health + /analytics/overview |

Invocar como:
```python
result = supabase.rpc("get_candidate_overview", {"p_candidate_id": str(candidate_id)}).execute()
```

### Extração de Stop Words para Wordcloud (NFR-003)

```python
from app.core.constants import PT_STOP_WORDS

def get_word_frequencies(texts: list[str], top_n: int = 200) -> list[WordEntry]:
    from collections import Counter
    words = []
    for text in texts:
        tokens = text.lower().split()
        words.extend(t for t in tokens if t not in PT_STOP_WORDS and len(t) > 2)
    return [WordEntry(word=w, count=c) for w, c in Counter(words).most_common(top_n)]
```

### THEME_KEYWORDS Structure (architecture.md Seção 4.3)

```python
THEME_KEYWORDS = {
    "saude": ["saude", "hospital", "medico", "sus", "vacina", "doenca", "saude"],
    "seguranca": ["seguranca", "policia", "violencia", "crime", "bandido", "furto"],
    "educacao": ["educacao", "escola", "professor", "ensino", "aluno", "universidade"],
    "economia": ["economia", "salario", "preco", "inflacao", "mercado"],
    "infraestrutura": ["obra", "asfalto", "saneamento", "rua", "ponte", "agua"],
    "corrupcao": ["corrupcao", "roubo", "desvio", "propina", "esquema"],
    "emprego": ["emprego", "trabalho", "desemprego", "carteira", "contratacao"],
    "meio_ambiente": ["ambiente", "lixo", "poluicao", "verde", "floresta"],
    "outros": []  # default
}
```

### Trend Direction Logic (architecture.md Seção 3.2.4 -- GET /analytics/comparison)

```
recent_5 = últimos 5 posts por posted_at DESC
previous_5 = posts 6-10 por posted_at DESC
recent_avg = AVG(sentiment) dos comentários dos recent_5 posts
previous_avg = AVG(sentiment) dos comentários dos previous_5 posts
delta = recent_avg - previous_avg
direction = "improving" if delta > 0.02 else "declining" if delta < -0.02 else "stable"
```

### Todos os Endpoints (architecture.md Seção 3.2.4)

| Endpoint | Método | Query Params |
|----------|--------|-------------|
| `/api/v1/analytics/overview` | GET | - |
| `/api/v1/analytics/sentiment-timeline` | GET | candidate_id, start_date, end_date |
| `/api/v1/analytics/wordcloud` | GET | candidate_id |
| `/api/v1/analytics/themes` | GET | candidate_id |
| `/api/v1/analytics/posts` | GET | candidate_id, sort_by, order, limit, offset |
| `/api/v1/analytics/comparison` | GET | - |

### Tabelas Envolvidas
- `candidates`, `posts`, `comments`, `sentiment_scores`, `themes` (todas em leitura)
- `themes` (escrita em `classify_all_unthemed_comments()`)

### PRD References
- FR-006: Overview Dashboard -- métricas side by side
- FR-007: Temporal Sentiment Chart -- dados de timeline
- FR-008: Word Cloud -- frequências excluindo stop words PT
- FR-009: Recurring Themes -- agrupamento temático keyword-based
- FR-010: Post Comparison -- lista ranqueada de posts
- FR-011: Candidate Comparison -- visão side-by-side com tendências
- NFR-001: Response Time < 2s para todos os endpoints de dados

---

## File List

| Arquivo | Acao |
|---------|------|
| `app/services/analytics.py` | Criar -- queries de agregação |
| `app/services/themes.py` | Criar -- classificação de temas |
| `app/routers/analytics.py` | Criar -- 6 endpoints GET |
| `app/models/analytics.py` | Modificar -- validar/completar modelos de resposta |
| `app/main.py` | Modificar -- registrar `analytics.router` |
| `tests/test_analytics.py` | Criar |
| `tests/test_themes.py` | Criar |

---

## Dev Notes

<!-- @dev: Espaço para anotar decisões durante implementação -->
<!-- Para wordcloud: normalizar texto (remover acentos, pontuação) antes de tokenizar -- usar unicodedata.normalize + regex -->
<!-- Para themes: normalizar texto sem acentos para matching (saude → saúde ambos devem dar match) -->
<!-- GET /analytics/posts: sort_by deve ser validado com Literal type annotation para evitar SQL injection (embora Supabase SDK parametrize) -->
<!-- Para comparison endpoint: se candidato tem < 5 posts, usar todos os posts disponíveis para recent_avg e previous_avg = None -->
<!-- As funções PL/pgSQL do migration 004 podem precisar ser adaptadas -- verificar assinaturas exatas antes de usar -->
<!-- Modelos de analytics.py (Story 1.1) podem precisar de ajustes depois de ver as respostas reais das funções PL/pgSQL -->

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
