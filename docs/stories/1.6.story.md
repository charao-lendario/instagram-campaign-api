# Story 1.6: Endpoints de Analytics e Comparação

## Status: InProgress
## Epic: 1 - Backend (FastAPI + Apify)
## Points: 8

---

## Description

Como estrategista de campanha, quero endpoints de API que agreguem e comparem dados de engajamento e sentimento entre candidatos e posts, para que o dashboard frontend possa renderizar todas as visualizações necessárias sem lógica de agregação no cliente.

Esta story implementa todos os endpoints do grupo `/api/v1/analytics/`, o serviço de extração de temas via keyword matching, e o serviço de analytics que agrega queries do Supabase. É a story de maior escopo do Epic 1 -- cobre 6 endpoints distintos e 2 serviços novos.

---

## Acceptance Criteria

- [x] **AC1**: Given que `GET /api/v1/analytics/overview` é chamado sem parâmetros, when processado, then retorna `200 OK` com a estrutura exata definida em `architecture.md` Seção 3.2.4 (campo `candidates` com array de métricas por candidato, `last_scrape`, `total_comments_analyzed`). Para cada candidato: `total_posts`, `total_comments`, `average_sentiment_score`, `sentiment_distribution` (positive/negative/neutral counts), `total_engagement` (sum likes + comment_counts de todos os posts).

- [x] **AC2**: Given que `GET /api/v1/analytics/sentiment-timeline` é chamado com parâmetros opcionais `candidate_id`, `start_date`, `end_date`, when processado, then retorna `200 OK` com lista de `data_points`, cada um contendo: `candidate_id`, `candidate_username`, `post_id`, `post_url`, `post_caption` (truncada em 100 chars), `posted_at`, `average_sentiment_score` (média do `vader_compound` dos comentários do post), `comment_count`. Quando `candidate_id` é omitido, retorna dados de ambos os candidatos. Quando datas são omitidas, padrão é últimos 30 dias.

- [x] **AC3**: Given que `GET /api/v1/analytics/wordcloud` é chamado com `candidate_id` opcional, when processado, then retorna `200 OK` com lista de `{word, count}` pairs, excluindo stop words em português definidas em `app/core/constants.py`. As palavras são extraídas de todos os `comments.text` do candidato (ou de ambos se `candidate_id` omitido), tokenizadas, lowercased, e contadas. Retornar no máximo 200 palavras ordenadas por count decrescente.

- [x] **AC4**: Given que `GET /api/v1/analytics/themes` é chamado com `candidate_id` opcional, when processado, then retorna `200 OK` com lista de objetos `{theme, count, percentage, by_candidate}`. O campo `by_candidate` contém contagens separadas por candidato. Percentagem calculada sobre o total de atribuições de tema. Fonte de dados: tabela `themes`.

- [x] **AC5**: Given que `GET /api/v1/analytics/posts` é chamado com parâmetros opcionais `candidate_id`, `sort_by`, `order`, `limit`, `offset`, when processado, then retorna `200 OK` com lista de posts com métricas calculadas: `post_id`, `candidate_username`, `url`, `caption` (truncada em 150 chars), `posted_at`, `like_count`, `comment_count`, `positive_ratio` (positive_count / total_comments), `negative_ratio`, `average_sentiment_score`. Suporta `sort_by` em qualquer das métricas numéricas e `order` asc/desc. Inclui `total`, `limit`, `offset` para paginação.

- [x] **AC6**: Given que `GET /api/v1/analytics/comparison` é chamado sem parâmetros, when processado, then retorna `200 OK` com array de 2 candidatos, cada um com: todos os campos de overview + `top_themes` (3 temas mais frequentes) + `trend` (`direction`, `recent_avg`, `previous_avg`, `delta`). O `trend` é calculado comparando a média de sentimento dos últimos 5 posts vs os 5 posts anteriores. `direction`: `"improving"` se delta > 0.02, `"declining"` se delta < -0.02, `"stable"` caso contrário.

- [x] **AC7**: Given que o serviço de extração de temas existe em `app/services/themes.py`, when `classify_comment_themes(comment_text: str) -> list[ThemeCreate]` é chamado, then: (a) o texto é lowercased e normalizado (sem acentos para matching); (b) cada keyword da lista `THEME_KEYWORDS` é verificada contra o texto; (c) um `ThemeCreate` com `method: "keyword"` e `confidence: 1.0` é criado para cada tema com match; (d) se nenhum match, retorna `[ThemeCreate(theme="outros", confidence=0.5, method="keyword")]`.

- [x] **AC8**: Given que `classify_all_unthemed_comments() -> int` existe em `app/services/themes.py`, when chamado, then: (a) busca todos os `comment_id` que não têm registro em `themes`; (b) para cada um, obtém o `text` e invoca `classify_comment_themes()`; (c) insere os `Theme` records no Supabase usando upsert com constraint `(comment_id, theme, method)`; (d) retorna o total de comentários processados.

- [x] **AC9**: Given que todos os endpoints de analytics são chamados com dados existentes, when processados, then respondem em menos de 2 segundos (NFR-001). Os endpoints que fazem queries complexas devem usar as funções PL/pgSQL definidas nas migrations (ex: `get_candidate_overview`, `get_sentiment_timeline`, `get_theme_distribution`, `get_post_rankings`) quando disponíveis.

- [x] **AC10**: Given que os unit tests existem em `tests/test_analytics.py`, when `pytest tests/test_analytics.py` é executado, then todos passam. Os testes cobrem: cada endpoint retorna a estrutura correta com dados mockados, comportamento com dados ausentes (candidato sem posts retorna zeros, não 404), e classificação de temas (keyword match, sem match → "outros").

---

## Scope

### IN
- `app/services/analytics.py` -- queries de agregação para cada endpoint
- `app/services/themes.py` -- `classify_comment_themes()`, `classify_all_unthemed_comments()`
- `app/routers/analytics.py` -- 6 endpoints GET de analytics
- Modelos de resposta em `app/models/analytics.py` (já definidos em Story 1.1, validar completude)
- `tests/test_analytics.py`
- `tests/test_themes.py`

### OUT
- Endpoint de suggestions (Story 1.7)
- LLM enrichment de temas ambíguos (além de keyword matching -- fora do MVP scope de temas)
- Dados em tempo real / WebSocket
- Cache de resultados de analytics

---

## Dependencies

- Story 1.1 concluída (modelos de analytics, cliente Supabase, constantes)
- Stories 1.2 + 1.3 concluídas (posts e comentários existem)
- Stories 1.4 + 1.5 concluídas (sentiment_scores preenchidos)
- Migrations `004_create_functions.sql` aplicadas no Supabase (funções PL/pgSQL)

---

## Technical Notes

### Funções PL/pgSQL Disponíveis (SCHEMA.md Seção 5)

Usar via `supabase.rpc()` para performance:

| Função | Endpoint que usa |
|--------|-----------------|
| `get_candidate_overview(candidate_id UUID)` | GET /analytics/overview |
| `get_sentiment_timeline(candidate_id, start, end)` | GET /analytics/sentiment-timeline |
| `get_theme_distribution(candidate_id)` | GET /analytics/themes |
| `get_post_rankings(candidate_id, sort_by, order, limit, offset)` | GET /analytics/posts |
| `get_comments_text_for_wordcloud(candidate_id, limit)` | GET /analytics/wordcloud |
| `get_candidate_comparison()` | GET /analytics/comparison |
| `get_last_successful_scrape()` | GET /health + /analytics/overview |

Invocar como:
```python
result = supabase.rpc("get_candidate_overview", {"p_candidate_id": str(candidate_id)}).execute()
```

### Extração de Stop Words para Wordcloud (NFR-003)

```python
from app.core.constants import PT_STOP_WORDS

def get_word_frequencies(texts: list[str], top_n: int = 200) -> list[WordEntry]:
    from collections import Counter
    words = []
    for text in texts:
        tokens = text.lower().split()
        words.extend(t for t in tokens if t not in PT_STOP_WORDS and len(t) > 2)
    return [WordEntry(word=w, count=c) for w, c in Counter(words).most_common(top_n)]
```

### THEME_KEYWORDS Structure (architecture.md Seção 4.3)

```python
THEME_KEYWORDS = {
    "saude": ["saude", "hospital", "medico", "sus", "vacina", "doenca", "saude"],
    "seguranca": ["seguranca", "policia", "violencia", "crime", "bandido", "furto"],
    "educacao": ["educacao", "escola", "professor", "ensino", "aluno", "universidade"],
    "economia": ["economia", "salario", "preco", "inflacao", "mercado"],
    "infraestrutura": ["obra", "asfalto", "saneamento", "rua", "ponte", "agua"],
    "corrupcao": ["corrupcao", "roubo", "desvio", "propina", "esquema"],
    "emprego": ["emprego", "trabalho", "desemprego", "carteira", "contratacao"],
    "meio_ambiente": ["ambiente", "lixo", "poluicao", "verde", "floresta"],
    "outros": []  # default
}
```

### Trend Direction Logic (architecture.md Seção 3.2.4 -- GET /analytics/comparison)

```
recent_5 = últimos 5 posts por posted_at DESC
previous_5 = posts 6-10 por posted_at DESC
recent_avg = AVG(sentiment) dos comentários dos recent_5 posts
previous_avg = AVG(sentiment) dos comentários dos previous_5 posts
delta = recent_avg - previous_avg
direction = "improving" if delta > 0.02 else "declining" if delta < -0.02 else "stable"
```

### Todos os Endpoints (architecture.md Seção 3.2.4)

| Endpoint | Método | Query Params |
|----------|--------|-------------|
| `/api/v1/analytics/overview` | GET | - |
| `/api/v1/analytics/sentiment-timeline` | GET | candidate_id, start_date, end_date |
| `/api/v1/analytics/wordcloud` | GET | candidate_id |
| `/api/v1/analytics/themes` | GET | candidate_id |
| `/api/v1/analytics/posts` | GET | candidate_id, sort_by, order, limit, offset |
| `/api/v1/analytics/comparison` | GET | - |

### Tabelas Envolvidas
- `candidates`, `posts`, `comments`, `sentiment_scores`, `themes` (todas em leitura)
- `themes` (escrita em `classify_all_unthemed_comments()`)

### PRD References
- FR-006: Overview Dashboard -- métricas side by side
- FR-007: Temporal Sentiment Chart -- dados de timeline
- FR-008: Word Cloud -- frequências excluindo stop words PT
- FR-009: Recurring Themes -- agrupamento temático keyword-based
- FR-010: Post Comparison -- lista ranqueada de posts
- FR-011: Candidate Comparison -- visão side-by-side com tendências
- NFR-001: Response Time < 2s para todos os endpoints de dados

---

## Risks

| Risco | Probabilidade | Impacto | Mitigacao |
|-------|---------------|---------|-----------|
| Funcoes PL/pgSQL do migration 004 podem ter assinaturas diferentes do esperado | Media | Alto | Verificar assinaturas exatas antes de usar; fallback para queries diretas via SDK se necessario |
| Performance dos endpoints de analytics acima de 2s com volume real de dados | Baixa | Alto | Usar funcoes PL/pgSQL server-side; indexes ja criados em Story 1.1; monitorar com timing logs |
| Keyword matching de temas com falsos positivos (ex: "trabalho" em contexto nao-emprego) | Alta | Baixo | Aceitavel para MVP; keyword matching e deterministico e auditavel; LLM enrichment fora do scope |
| Modelos Pydantic de analytics.py (Story 1.1) incompletos para as respostas reais | Media | Medio | Validar e completar modelos antes de implementar endpoints; File List ja inclui "Modificar" |
| Stop words PT insuficientes gerando wordcloud poluida | Baixa | Baixo | Usar lista curada em constants.py; ajustar iterativamente pos-deploy |

---

## File List

| Arquivo | Acao | Status |
|---------|------|--------|
| `app/services/analytics.py` | Criar -- queries de agregação via supabase.rpc() | Done |
| `app/services/themes.py` | Criar -- classificação de temas por keyword matching | Done |
| `app/routers/analytics.py` | Criar -- 6 endpoints GET | Done |
| `app/models/analytics.py` | Validar -- modelos já completos da Story 1.1, sem alterações necessárias | Done (sem mudanças) |
| `app/main.py` | Modificar -- registrar `analytics.router` | Done |
| `tests/test_analytics.py` | Criar -- 11 testes (endpoints + service + edge cases) | Done |
| `tests/test_themes.py` | Criar -- 9 testes (keyword matching + batch processing) | Done |
| `tests/test_config.py` | Modificar -- atualizar testes de health para novo comportamento (503 + rpc mock) | Done |

---

## Dev Notes

- **[AUTO-DECISION] Modelos analytics.py**: Os modelos Pydantic definidos na Story 1.1 estavam completos e não precisaram de alterações. O File List original indicava "Modificar" mas não houve necessidade.
- **Wordcloud**: Implementado `_normalize_text()` usando `unicodedata.normalize("NFKD")` para remover acentos + `re.sub` para pontuação. Tokenização por `.split()` com filtro de stop words (`PT_STOP_WORDS` de constants.py) e palavras com len <= 2.
- **Themes**: `_normalize_text()` reutilizado para matching de keywords sem acentos. Funciona para ambos inputs: "educação" e "educacao" dão match em "educacao".
- **sort_by validation**: Usado `Literal` type annotation no endpoint `/posts` para validar valores aceitos. FastAPI retorna 422 automaticamente para valores inválidos.
- **Comparison trend**: Quando candidato tem < 10 posts, `get_candidate_comparison` RPC calcula com os posts disponíveis. Se < 5 posts, `previous_avg` pode ser None e direction = "stable".
- **RPC functions**: Todas as 7 funções PL/pgSQL do migration 004 foram utilizadas via `supabase.rpc()`. Assinaturas compatíveis sem adaptação.
- **sort_by mapping**: O endpoint aceita `sentiment_score` como sort_by mas mapeia para `avg_sentiment` internamente (nome usado pela função PL/pgSQL).
- **Health endpoint breaking change**: A integração do scheduler na Story 1.7 alterou o health endpoint para retornar 503 quando DB está down (era 200). Testes pré-existentes em `test_config.py` foram atualizados.

---

## Validation

| # | Criterio | Resultado |
|---|----------|-----------|
| 1 | Titulo claro e objetivo | PASS |
| 2 | Descricao completa (problema/necessidade) | PASS |
| 3 | Criterios de aceitacao testaveis (Given/When/Then) | PASS |
| 4 | Escopo bem definido (IN e OUT) | PASS |
| 5 | Dependencias mapeadas | PASS |
| 6 | Estimativa de complexidade | PASS |
| 7 | Valor de negocio claro | PASS |
| 8 | Riscos documentados | PASS (adicionado durante validacao) |
| 9 | Criterios de Done claros | PASS |
| 10 | Alinhamento com PRD/Epic | PASS |

**Score: 9/10 -> GO**
**Validado por:** Pax (PO) em 2026-02-21
**Nota:** Secao de Riscos ausente na criacao, adicionada durante validacao.

---

## Change Log

| Data | Autor | Descricao |
|------|-------|-----------|
| 2026-02-21 | River (SM) | Story criada |
| 2026-02-21 | Pax (PO) | Validacao: GO 9/10. Adicionada secao Risks. Status Draft -> Ready |
| 2026-02-21 | Dex (Dev) | Status Ready -> InProgress. Implementacao completa: analytics.py (service), themes.py (service), analytics.py (router), test_analytics.py, test_themes.py. Todos ACs marcados [x]. 20 testes passando. |
